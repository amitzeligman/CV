{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitzeligman/CV/blob/master/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "u3wrZWoalNEv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from functools import reduce\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "def rand(a=0, b=1):\n",
        "    return np.random.rand()*(b-a) + a\n",
        "\n",
        "\n",
        "def compose(*funcs):\n",
        "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
        "    Reference: https://mathieularose.com/function-composition-in-python/\n",
        "    \"\"\"\n",
        "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
        "    if funcs:\n",
        "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
        "    else:\n",
        "        raise ValueError('Composition of empty sequence not supported.')\n",
        "\n",
        "\n",
        "def box_iou(b1, b2):\n",
        "    '''Return iou tensor\n",
        "    Parameters\n",
        "    ----------\n",
        "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
        "    b2: tensor, shape=(j, 4), xywh\n",
        "    Returns\n",
        "    -------\n",
        "    iou: tensor, shape=(i1,...,iN, j)\n",
        "    '''\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b1 = K.expand_dims(b1, -2)\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh/2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b2 = K.expand_dims(b2, 0)\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh/2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
        "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape(-1, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tZy6GigulweE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
        "from utils import rand\n",
        "import os\n",
        "\n",
        "\n",
        "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
        "    \"\"\"Pre process true boxes to training input format\n",
        "    Parameters\n",
        "    ----------\n",
        "    true_boxes: array, shape=(m, T, 5)\n",
        "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n",
        "    input_shape: array-like, hw, multiples of 32\n",
        "    anchors: array, shape=(N, 2), wh\n",
        "    num_classes: integer\n",
        "    Returns\n",
        "    -------\n",
        "    y_true: list of array, shape like yolo_outputs, xywh are relative value\n",
        "    \"\"\"\n",
        "    assert (true_boxes[..., 4] < num_classes).all(), 'class id must be less than num_classes'\n",
        "    num_layers = len(anchors)//3\n",
        "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
        "\n",
        "    true_boxes = np.array(true_boxes, dtype='float32')\n",
        "    input_shape = np.array(input_shape, dtype='int32')\n",
        "\n",
        "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
        "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
        "    true_boxes[..., 0:2] = boxes_xy/input_shape[::-1]\n",
        "    true_boxes[..., 2:4] = boxes_wh/input_shape[::-1]\n",
        "\n",
        "    m = true_boxes.shape[0]\n",
        "    grid_shapes = [input_shape//{0: 32, 1: 16, 2: 8}[l] for l in range(num_layers)]\n",
        "    y_true = [np.zeros((m, grid_shapes[l][0], grid_shapes[l][1], len(anchor_mask[l]), 5 + num_classes),\n",
        "                       dtype='float32') for l in range(num_layers)]\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    anchors = np.expand_dims(anchors, 0)\n",
        "    anchor_maxes = anchors / 2.\n",
        "    anchor_mins = -anchor_maxes\n",
        "    valid_mask = boxes_wh[..., 0] > 0\n",
        "\n",
        "    for b in range(m):\n",
        "        # Discard zero rows.\n",
        "        wh = boxes_wh[b, valid_mask[b]]\n",
        "        if len(wh) == 0:\n",
        "            continue\n",
        "        # Expand dim to apply broadcasting.\n",
        "        wh = np.expand_dims(wh, -2)\n",
        "        box_maxes = wh / 2.\n",
        "        box_mins = -box_maxes\n",
        "\n",
        "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
        "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
        "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        box_area = wh[..., 0] * wh[..., 1]\n",
        "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
        "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
        "\n",
        "        # Find best anchor for each true box\n",
        "        best_anchor = np.argmax(iou, axis=-1)\n",
        "\n",
        "        for t, n in enumerate(best_anchor):\n",
        "            for l in range(num_layers):\n",
        "                if n in anchor_mask[l]:\n",
        "                    i = np.floor(true_boxes[b, t, 0]*grid_shapes[l][1]).astype('int32')\n",
        "                    j = np.floor(true_boxes[b, t, 1]*grid_shapes[l][0]).astype('int32')\n",
        "                    k = anchor_mask[l].index(n)\n",
        "                    c = true_boxes[b, t, 4].astype('int32')\n",
        "                    y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]\n",
        "                    y_true[l][b, j, i, k, 4] = 1\n",
        "                    y_true[l][b, j, i, k, 5+c] = 1\n",
        "\n",
        "    return y_true\n",
        "\n",
        "\n",
        "def get_random_data(annotation_line, input_shape, imageDir, random=True, max_boxes=20, jitter=.3, hue=.1, sat=1.5, val=1.5, proc_img=True):\n",
        "    \"\"\"random pre processing for real-time data augmentation\"\"\"\n",
        "    line = annotation_line.split(':')\n",
        "    imageName = line[0]\n",
        "    boxes = line[1].replace('[', '')\n",
        "    boxes = boxes.replace(']\\n', '')\n",
        "    boxes = boxes.split('],')\n",
        "\n",
        "    imagePath = os.path.join(imageDir, imageName)\n",
        "    image = Image.open(imagePath)\n",
        "    iw, ih = image.size\n",
        "    h, w = input_shape\n",
        "    box = np.array([np.array(list(map(int, box.split(',')))) for box in boxes])\n",
        "    # fix to absolute coordinates\n",
        "    box[..., 2:4] = box[..., 0:2] + box[..., 2:4]\n",
        "    if not random:\n",
        "        # resize image\n",
        "        scale = min(w/iw, h/ih)\n",
        "        nw = int(iw*scale)\n",
        "        nh = int(ih*scale)\n",
        "        dx = (w-nw)//2\n",
        "        dy = (h-nh)//2\n",
        "        image_data = 0\n",
        "        if proc_img:\n",
        "            image = image.resize((nw, nh), Image.BICUBIC)\n",
        "            new_image = Image.new('RGB', (w, h), (128, 128, 128))\n",
        "            new_image.paste(image, (dx, dy))\n",
        "            image_data = np.array(new_image)/255.\n",
        "\n",
        "        # correct boxes\n",
        "        box[..., 4] -= 1     # change the classes numerator to start from 0\n",
        "        box_data = np.zeros((max_boxes, 5))\n",
        "        if len(box) > 0:\n",
        "            np.random.shuffle(box)\n",
        "            if len(box) > max_boxes:\n",
        "                box = box[:max_boxes]\n",
        "            box[:, [0, 2]] = box[:, [0, 2]]*scale + dx\n",
        "            box[:, [1, 3]] = box[:, [1, 3]]*scale + dy\n",
        "            box_data[:len(box)] = box\n",
        "\n",
        "        return image_data, box_data\n",
        "\n",
        "    # resize image\n",
        "    new_ar = w/h * rand(1-jitter, 1+jitter)/rand(1-jitter, 1+jitter)\n",
        "    scale = rand(.25, 2)\n",
        "    if new_ar < 1:\n",
        "        nh = int(scale*h)\n",
        "        nw = int(nh*new_ar)\n",
        "    else:\n",
        "        nw = int(scale*w)\n",
        "        nh = int(nw/new_ar)\n",
        "    image = image.resize((nw, nh), Image.BICUBIC)\n",
        "\n",
        "    # place image\n",
        "    dx = int(rand(0, w-nw))\n",
        "    dy = int(rand(0, h-nh))\n",
        "    new_image = Image.new('RGB', (w, h), (128, 128, 128))\n",
        "    new_image.paste(image, (dx, dy))\n",
        "    image = new_image\n",
        "\n",
        "    # flip image or not\n",
        "    flip = rand() < .5\n",
        "    if flip:\n",
        "        image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "    # distort image\n",
        "    hue = rand(-hue, hue)\n",
        "    sat = rand(1, sat) if rand() < .5 else 1/rand(1, sat)\n",
        "    val = rand(1, val) if rand() < .5 else 1/rand(1, val)\n",
        "    x = rgb_to_hsv(np.array(image)/255.)\n",
        "    x[..., 0] += hue\n",
        "    x[..., 0][x[..., 0] > 1] -= 1\n",
        "    x[..., 0][x[..., 0] < 0] += 1\n",
        "    x[..., 1] *= sat\n",
        "    x[..., 2] *= val\n",
        "    x[x > 1] = 1\n",
        "    x[x < 0] = 0\n",
        "    image_data = hsv_to_rgb(x) # numpy array, 0 to 1\n",
        "\n",
        "    # correct boxes\n",
        "    box[..., 4] -= 1    # change the classes numerator to start from 0\n",
        "    box_data = np.zeros((max_boxes, 5))\n",
        "    if len(box) > 0:\n",
        "        np.random.shuffle(box)\n",
        "        box[:, [0, 2]] = box[:, [0, 2]]*nw/iw + dx\n",
        "        box[:, [1, 3]] = box[:, [1, 3]]*nh/ih + dy\n",
        "        if flip:\n",
        "            box[:, [0, 2]] = w - box[:, [2, 0]]\n",
        "        box[:, 0:2][box[:, 0:2] < 0] = 0\n",
        "        box[:, 2][box[:, 2] > w] = w\n",
        "        box[:, 3][box[:, 3] > h] = h\n",
        "        box_w = box[:, 2] - box[:, 0]\n",
        "        box_h = box[:, 3] - box[:, 1]\n",
        "        box = box[np.logical_and(box_w > 1, box_h > 1)]  # discard invalid box\n",
        "        if len(box) > max_boxes:\n",
        "            box = box[:max_boxes]\n",
        "        box_data[:len(box)] = box\n",
        "\n",
        "    return image_data, box_data\n",
        "\n",
        "\n",
        "def get_meta_data(annotation_path, val_split=0.1):\n",
        "    with open(annotation_path) as f:\n",
        "        lines = f.readlines()\n",
        "    np.random.seed(10101)\n",
        "    np.random.shuffle(lines)\n",
        "    np.random.seed(None)\n",
        "    num_val = int(len(lines)*val_split)\n",
        "    num_train = len(lines) - num_val\n",
        "    train_annotations = lines[:num_train]\n",
        "    validation_annotations = lines[num_train:]\n",
        "    return train_annotations, validation_annotations\n",
        "\n",
        "# TODO - pay attention to the changes here\n",
        "\n",
        "\n",
        "def data_generator(annotation_lines, imagesDir, batch_size, input_shape, anchors, num_classes):\n",
        "    \"\"\"data generator for fit_generator\"\"\"\n",
        "    n = len(annotation_lines)\n",
        "    i = 0\n",
        "    while True:\n",
        "        image_data = []\n",
        "        box_data = []\n",
        "        for b in range(batch_size):\n",
        "            if i == 0:\n",
        "                np.random.shuffle(annotation_lines)\n",
        "            image, box = get_random_data(annotation_lines[i], input_shape, imagesDir, random=True)\n",
        "            image_data.append(image)\n",
        "            box_data.append(box)\n",
        "            i = (i+1) % n\n",
        "        image_data = np.array(image_data)\n",
        "        box_data = np.array(box_data)\n",
        "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "        yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "\n",
        "def data_generator_wrapper(annotation_lines,imagesDir, batch_size, input_shape, anchors, num_classes):\n",
        "    n = len(annotation_lines)\n",
        "    if n == 0 or batch_size <= 0:\n",
        "        return None\n",
        "    return data_generator(annotation_lines,imagesDir, batch_size, input_shape, anchors, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-RO04c7Xl-UC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "class YOLO_Kmeans:\n",
        "\n",
        "    def __init__(self, cluster_number, filename):\n",
        "        self.cluster_number = cluster_number\n",
        "        self.filename = filename\n",
        "\n",
        "    def iou(self, boxes, clusters):  # 1 box -> k clusters\n",
        "        n = boxes.shape[0]\n",
        "        k = self.cluster_number\n",
        "\n",
        "        box_area = boxes[:, 0] * boxes[:, 1]\n",
        "        box_area = box_area.repeat(k)\n",
        "        box_area = np.reshape(box_area, (n, k))\n",
        "\n",
        "        cluster_area = clusters[:, 0] * clusters[:, 1]\n",
        "        cluster_area = np.tile(cluster_area, [1, n])\n",
        "        cluster_area = np.reshape(cluster_area, (n, k))\n",
        "\n",
        "        box_w_matrix = np.reshape(boxes[:, 0].repeat(k), (n, k))\n",
        "        cluster_w_matrix = np.reshape(np.tile(clusters[:, 0], (1, n)), (n, k))\n",
        "        min_w_matrix = np.minimum(cluster_w_matrix, box_w_matrix)\n",
        "\n",
        "        box_h_matrix = np.reshape(boxes[:, 1].repeat(k), (n, k))\n",
        "        cluster_h_matrix = np.reshape(np.tile(clusters[:, 1], (1, n)), (n, k))\n",
        "        min_h_matrix = np.minimum(cluster_h_matrix, box_h_matrix)\n",
        "        inter_area = np.multiply(min_w_matrix, min_h_matrix)\n",
        "\n",
        "        result = inter_area / (box_area + cluster_area - inter_area)\n",
        "        return result\n",
        "\n",
        "    def avg_iou(self, boxes, clusters):\n",
        "        accuracy = np.mean([np.max(self.iou(boxes, clusters), axis=1)])\n",
        "        return accuracy\n",
        "\n",
        "    def kmeans(self, boxes, k, dist=np.median):\n",
        "        box_number = boxes.shape[0]\n",
        "        distances = np.empty((box_number, k))\n",
        "        last_nearest = np.zeros((box_number,))\n",
        "        np.random.seed()\n",
        "        clusters = boxes[np.random.choice(\n",
        "            box_number, k, replace=False)]  # init k clusters\n",
        "        while True:\n",
        "\n",
        "            distances = 1 - self.iou(boxes, clusters)\n",
        "\n",
        "            current_nearest = np.argmin(distances, axis=1)\n",
        "            if (last_nearest == current_nearest).all():\n",
        "                break  # clusters won't change\n",
        "            for cluster in range(k):\n",
        "                clusters[cluster] = dist(  # update clusters\n",
        "                    boxes[current_nearest == cluster], axis=0)\n",
        "\n",
        "            last_nearest = current_nearest\n",
        "\n",
        "        return clusters\n",
        "\n",
        "    def result2txt(self, data):\n",
        "        f = open(\"yolo_anchors.txt\", 'w')\n",
        "        row = np.shape(data)[0]\n",
        "        for i in range(row):\n",
        "            if i == 0:\n",
        "                x_y = \"%d,%d\" % (data[i][0], data[i][1])\n",
        "            else:\n",
        "                x_y = \", %d,%d\" % (data[i][0], data[i][1])\n",
        "            f.write(x_y)\n",
        "        f.close()\n",
        "\n",
        "    def txt2boxes(self):\n",
        "        f = open(self.filename, 'r')\n",
        "        dataSet = []\n",
        "        for line in f:\n",
        "            line = line.split(':')\n",
        "            boxes = line[1].replace('[', '')\n",
        "            boxes = boxes.replace(']\\n', '')\n",
        "            boxes = boxes.split('],')\n",
        "            length = len(boxes)\n",
        "            for i in range(length):\n",
        "\n",
        "                width = int(boxes[i].split(\",\")[2])\n",
        "                height = int(boxes[i].split(\",\")[3])\n",
        "                dataSet.append([width, height])\n",
        "        result = np.array(dataSet)\n",
        "        f.close()\n",
        "        return result\n",
        "\n",
        "    def txt2clusters(self):\n",
        "        all_boxes = self.txt2boxes()\n",
        "        result = self.kmeans(all_boxes, k=self.cluster_number)\n",
        "        result = result[np.lexsort(result.T[0, None])]\n",
        "        self.result2txt(result)\n",
        "        print(\"K anchors:\\n {}\".format(result))\n",
        "        print(\"Accuracy: {:.2f}%\".format(\n",
        "            self.avg_iou(all_boxes, result) * 100))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Define main paths\n",
        "    projectDir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "    busDetectorDir = (os.path.dirname(os.path.abspath(__file__)))\n",
        "    dataDir = os.path.join(projectDir, \"Data\")\n",
        "    annotationsPath = os.path.join(dataDir, 'annotationsTrain.txt')\n",
        "    cluster_number = 9\n",
        "    kmeans = YOLO_Kmeans(cluster_number, annotationsPath)\n",
        "    kmeans.txt2clusters()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YqB0V1NpmHTH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from model import create_model\n",
        "from dataLoader import data_generator_wrapper\n",
        "import dataLoader\n",
        "import os\n",
        "from keras.utils import plot_model\n",
        "from utils import get_anchors\n",
        "from kmeans import YOLO_Kmeans\n",
        "\n",
        "\n",
        "# Define main paths\n",
        "projectDir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
        "busDetectorDir = (os.path.dirname(os.path.abspath(__file__)))\n",
        "dataDir = os.path.join(projectDir, \"Data\")\n",
        "annotationsPath = os.path.join(dataDir, 'annotationsTrain.txt')\n",
        "imagesDir = os.path.join(dataDir, \"busesTrain\")\n",
        "logDir = os.path.join(busDetectorDir, 'logs/000/')\n",
        "\n",
        "# Anchors\n",
        "anchors = get_anchors('yolo_anchors.txt')\n",
        "anchors = [10, 13,  16, 30,  33, 23,  30, 61,  62, 45,  59, 119,  116, 90,  156, 198,  373, 326]\n",
        "anchors = np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "# Classes\n",
        "classes = ['green', 'orange', 'white', 'silver', 'blue', 'red']\n",
        "num_classes = len(classes)\n",
        "\n",
        "input_shape = (3648, 2736)\n",
        "\n",
        "# Hyper parameters\n",
        "\n",
        "batch_size = 32\n",
        "val_split = 0.1\n",
        "learningRate = 1e-3\n",
        "\n",
        "\n",
        "# Create model\n",
        "\n",
        "model = create_model(input_shape, anchors, num_classes,\n",
        "                     freeze_body=2, weights_path='model_data/yolo_weights.h5')  # make sure you know what you freeze\n",
        "\n",
        "plot_model(model, to_file='model.png')\n",
        "logging = TensorBoard(log_dir=logDir)\n",
        "checkpoint = ModelCheckpoint(logDir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "                             monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "\n",
        "train_annotations, validation_annotations = dataLoader.get_meta_data(annotationsPath, val_split=val_split)\n",
        "\n",
        "num_train = len(train_annotations)\n",
        "num_val = len(validation_annotations)\n",
        "\n",
        "# Train with frozen layers first, to get a stable loss.\n",
        "# Adjust num epochs to your data set. This step is enough to obtain a not bad model.\n",
        "if True:\n",
        "    model.compile(optimizer=Adam(lr=learningRate), loss={\n",
        "        # use custom yolo_loss Lambda layer.\n",
        "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "\n",
        "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "    model.fit_generator(data_generator_wrapper(train_annotations, imagesDir,  batch_size, input_shape, anchors, num_classes),\n",
        "                        steps_per_epoch=max(1, num_train // batch_size),\n",
        "                        validation_data=data_generator_wrapper(validation_annotations, imagesDir,  batch_size, input_shape, anchors,\n",
        "                                                               num_classes),\n",
        "                        validation_steps=max(1, num_val // batch_size),\n",
        "                        epochs=50,\n",
        "                        initial_epoch=0,\n",
        "                        callbacks=[logging, checkpoint])\n",
        "    model.save_weights(logDir + 'trained_weights_stage_1.h5')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}